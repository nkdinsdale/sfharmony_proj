<script src="http://www.google.com/jsapi" type="text/javascript"></script> 
<script type="text/javascript">google.load("jquery", "1.3.2");</script>

<style type="text/css">
	body {
		font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif; 
		font-weight:300;
		font-size:18px;
		margin-left: auto;
		margin-right: auto;
		width: 1100px;
	}
	
	h1 {
		font-size:32px;
		font-weight:300;
	}
	
	.disclaimerbox {
		background-color: #eee;		
		border: 1px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
		padding: 20px;
	}

	video.header-vid {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	img.header-img {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	img.rounded {
		border: 1px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	a:link,a:visited
	{
		color: #1367a7;
		text-decoration: none;
	}
	a:hover {
		color: #208799;
	}
	
	td.dl-link {
		height: 160px;
		text-align: center;
		font-size: 22px;
	}
	
	.layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		5px 5px 0 0px #fff, /* The second layer */
		5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		10px 10px 0 0px #fff, /* The third layer */
		10px 10px 1px 1px rgba(0,0,0,0.35), /* The third layer shadow */
		15px 15px 0 0px #fff, /* The fourth layer */
		15px 15px 1px 1px rgba(0,0,0,0.35), /* The fourth layer shadow */
		20px 20px 0 0px #fff, /* The fifth layer */
		20px 20px 1px 1px rgba(0,0,0,0.35), /* The fifth layer shadow */
		25px 25px 0 0px #fff, /* The fifth layer */
		25px 25px 1px 1px rgba(0,0,0,0.35); /* The fifth layer shadow */
		margin-left: 10px;
		margin-right: 45px;
	}

	.paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		0px 0px 1px 1px rgba(0,0,0,0.35); /* The top layer shadow */

		margin-left: 10px;
		margin-right: 45px;
	}


	.layered-paper { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		5px 5px 0 0px #fff, /* The second layer */
		5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		10px 10px 0 0px #fff, /* The third layer */
		10px 10px 1px 1px rgba(0,0,0,0.35); /* The third layer shadow */
		margin-top: 5px;
		margin-left: 10px;
		margin-right: 30px;
		margin-bottom: 5px;
	}
	
	.vert-cent {
		position: relative;
		top: 50%;
		transform: translateY(-50%);
	}
	
	hr
	{
		border: 0;
		height: 1px;
		background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
	}
</style>

<html>
<head>
	<title>SFHarmony: Source Free Domain Adaptation for Distributed Neuroimaging Analysis </title>
	<meta property="og:image" content="Path to my teaser.png"/> <!-- Facebook automatically scrapes this. Go to https://developers.facebook.com/tools/debug/ if you update and want to force Facebook to rescrape. -->
	<meta property="og:title" content="SFHarmony: Source Free Domain Adaptation for Distributed Neuroimaging Analysis" />
	<meta property="og:description" content="Paper description." />

	<!-- Get from Google Analytics -->
	<!-- Global site tag (gtag.js) - Google Analytics -->
	<script async src=""></script> 
	<script>
		window.dataLayer = window.dataLayer || [];
		function gtag(){dataLayer.push(arguments);}
		gtag('js', new Date());

		gtag('config', 'UA-75863369-6');
	</script>
</head>

<body>
	<br>
	<center>
		<span style="font-size:36px">SFHarmony: Source Free Domain Adaptation for Distributed Neuroimaging Analysis </span>
		<br>
		<br>
		<center><font size="+2"><i>ICCV 2023 [To be presented] </font></center>
		<table align=center width=600px>
			<table align=center width=600px>
				<tr>
					<td align=center width=130px>
						<center>
							<span style="font-size:24px"><a href="https://nkdinsdale.github.io/nkdinsdale/">Nicola Dinsdale</a><sup>1</sup></span>
						</center>
					</td>
					<td align=center width=100px>
						<center>
							<span style="font-size:24px"><a href="https://www.ndcn.ox.ac.uk/team/mark-jenkinson">Mark Jenkinson</a><sup>2,</sup><sup>3,</sup><sup>4</sup></span>
						</center>
					</td>
					<td align=center width=100px>
						<center>
							<span style="font-size:24px"><a href="https://www.pmb.ox.ac.uk/person/dr-ana-namburete">Ana Namburete</a><sup>1,</sup><sup>2</sup></span>
						</center>
					</td>
				</tr>
			</table>

					<br>
			<table align=center width=800px>
				<tr>
					<td align=center width=800px>
						<center>
							<span style="font-size:12px"><sup>1</sup>Oxford Machine Learning in NeuroImaging (OMNI) Lab,  University of Oxford</a></span>
						</center>
					</td>
				</tr>
			</table>

			<table align=center width=800px>
				<tr>
					<td align=center width=800px>
						<center>
							<span style="font-size:12px"><sup>2</sup>Wellcome Institute for Integrative NeuroImaging (WIN), University of Adelaide </a></span>
						</center>
					</td>
				</tr>
			</table>

			<table align=center width=800px>
				<tr>
					<td align=center width=800px>
						<center>
							<span style="font-size:12px"><sup>3</sup>Australian Institute for Machine Learning (AIML), University of Adelaide </a></span>
						</center>
					</td>
				</tr>
			</table>

			<table align=center width=800px>
				<tr>
					<td align=center width=800px>
						<center>
							<span style="font-size:12px"><sup>4</sup>South Australian Health and Medical Research Institute (SAHMRI) </a></span>
						</center>
					</td>
				</tr>
			</table>


			<table align=center width=500px>
				<tr>
					<td align=center width=200px>
						<center>
							<span style="font-size:24px"><a href=https://arxiv.org/abs/2303.15965>[Paper]</a></span>
						</center>
					</td>
					<td align=center width=120px>
						<center>
							<span style="font-size:24px"><a href=https://github.com/nkdinsdale/SFHarmony>[GitHub]</a></span><br>
						</center>
					</td>
				</tr>
			</table>
		</table>
	</center>

	<center>
		<table align=center width=1000px>
			<tr>
				<td width=1000px>
					<center>
						<img class="round" style="width:1000px" src="./resources/figure.png"/>
					</center>
				</td>
			</tr>
		</table>
	</center>

	<hr>

	<table align=center width=850px>
		<center><h1>Abstract</h1></center>
		<tr>
			<td>
				To represent the biological variability of clinical neuroimaging populations, it is vital to be able to combine data across scanners and studies. However, different MRI scanners produce images with different characteristics, resulting in a domain shift known as the `harmonisation problem'. Additionally, neuroimaging data is inherently personal in nature, leading to data privacy concerns when sharing the data. To overcome these barriers, we propose an Unsupervised Source-Free Domain Adaptation (SFDA) method, SFHarmony. Through modelling the imaging features as a Gaussian Mixture Model and minimising an adapted Bhattacharyya distance between the source and target features, we can create a model that performs well for the target data whilst having a shared feature representation across the data domains, without needing access to the source data for adaptation or target labels. We demonstrate the performance of our method on simulated and real domain shifts, showing that the approach is applicable to classification, segmentation and regression tasks, requiring no changes to the algorithm. Our method outperforms existing SFDA approaches across a range of realistic data scenarios, demonstrating the potential utility of our approach for MRI harmonisation and general SFDA problems.
			</td>
		</tr>
	</table>
	<br>

	<center><h1>SFHarmony</h1></center>

	<table align=center width=420px>
		<center>
			<tr>
				<td>
				</td>
			</tr>
		</center>
	</table>
	<table align=center width=400px>
		<tr>
			<td align=center width=400px>
				<center>
						<img class="round" style="width:700px" src="./resources/constant_lines.png"/>
				</center>
			</td>
		</tr>
	</table>
	<table align=center width=850px>
		<center>
			<tr>
				<td>
					We explore an unsupervised DA setting where
					only the source model, instead of the source data, is pro-
					vided to the unlabelled target domain for harmonisation,
					known as Source Free Domain Adaptation (SFDA). This
					setting inherently protects individual privacy, whilst allow-
					ing the efficient incorporation of new sites without requiring
					target labels. We propose a simple yet effective solution,
					termed SFHarmony, which aims to match feature embed-
					dings from the source and target, through characterising the
					embeddings as a Gaussian Mixture model (GMM) and the
					use of a modified Bhattacharyya distance. We demonstrate the approach for classification, segmentation and regression tasks.
				</td>
			</tr>
		</center>
	</table>


	<table align=center width=850px>
		<center>
			<tr>
				<td>
					Our contributions are as follows: 
				</td>
			</tr>
		</center>
	</table>
	<table align=center width=850px>
		<center>
			<tr>
				<td>
					- We propose a new method for SFDA, SFHarmony, based on aligning feature
	embeddings, utilising a modified Bhattacharyya distance,
	requiring no changes to source training; 
				</td>
			</tr>
		</center>
	</table>

	<table align=center width=850px>
		<center>
			<tr>
				<td>
					- We demonstrate the methodâ€™s applicability to classification, segmentation and regression tasks, and show that the approach
	outperforms existing SFDA methods for domain shifts experienced when working with neuroimaging data;
				</td>
			</tr>
		</center>
	</table>

	<table align=center width=850px>
		<center>
			<tr>
				<td>

					-  We demonstrate the robustness of the method to additional challenges likely to be faced when working with real world
					imaging data: differential privacy and label imbalance.
				</td>
			</tr>
		</center>
	</table>


	<table align=center width=800px>
		<br>
		<tr><center>
			<span style="font-size:28px">&nbsp;<a href='https://github.com/nkdinsdale/SFHarmony'>[GitHub]</a>
			</center>
		</span>
	</table>
	<br>

		<center><h1>Results</h1></center>
	<center><font size="+2"><i>Classification </font></center>
		<tr>
			<td width=1000px>
        		<center>
        			<img class="round" style="width:700px" src="./resources/classification_results.png"/>
        		</center>
        	</td>
		</tr>
	</table>


	<tr>
		<td width=1000px>
			<center>
				<img class="round" style="width:700px" src="./resources/features.png"/>
			</center>
		</td>
	</tr>

	<br>

	<tr>
    	<td>
			<center>
				<font size="-0.5"> We applied synthetic shifts to the OrganMNist dataset to simulate shifts expected when working with MRI data. We compared to state of the art methods, and showed our approach outperformed existing methods for a range of batchsizes.</font>
    		</center>

		</td>
    </tr>

	<tr>
    	<td>

		</td>
    </tr>
	<br>
	<br>

	<tr>
    	<td>
			<center>
				<font size="-0.5"> We also considered two additional challenges: differential privacy and label imbalance. We found that our approach was robust to both.</font>
    		</center>

		</td>
    </tr>


	<tr>
		<td width=1000px>
			<center>
				<img class="round" style="width:400px" src="./resources/differential_privacy.png"/>
			</center>
		</td>
	</tr>

	<tr>
		<td width=1000px>
			<center>
				<img class="round" style="width:400px" src="./resources/remove_labels.png"/>
			</center>
		</td>
	</tr>


	<br>
	<center><font size="+2"><i>Segmentation</font></center>
			<tr>
			<td width=1000px>
        		<center>
        			<img class="round" style="width:800px" src="./resources/segmentation_results.png"/>
        		</center>
        	</td>
		</tr>

		<tr>
    	<td>
			<center>
				<font size="-0.5"> We considered two segmentation tasks: brain extraction (CC359) and tissue segmentation (ABIDE) using multisite datasets. We outperformed the existing methods for segmentation, including domain specific approaches. </font>
    		</center>

		</td>
    </tr>


	<center><font size="+2"><i>Regression</font></center>
		<tr>
			<td width=1000px>
        		<center>
        			<img class="round" style="width:800px" src="./resources/regression_results.png"/>
        		</center>
        	</td>
		</tr>

		<tr>
    	<td>
			<center>
				<font size="-0.5"> We considered age prediction with the ABIDE data for the regression task. No existing SFDA approaches can be used for regression. </font>
    		</center>

		</td>
    </tr>

	<hr>
	<br>
		<table align=center width=850px>
			<center>
				<tr>
					<td>
						<center><h1>Conclusion</h1></center>

						We have presented SFHarmony, a method for SFDA,
						motivated by the need to harmonise MRI data across imaging sites while relaxing assumptions about the availability
						of source data. We have demonstrated the applicability of
						the method to classification, regression, and segmentation
						tasks, and have shown that it outperforms existing SFDA
						approaches when applied to MR imaging data. The approach is general, allowing it to be applied across architectures and tasks. Issues may arise due the increase in features
						when applying the approach to 3D volumes. Currently, the
						approach models each feature as an independent GMM, but
						features will be highly related within a filter and approaches
						to utilise these relations should be explored.
					</td>
				</tr>
			</center>
		</table>

	<br>

	<table align=center width=900px>
		<tr>
			<td width=300px>
				<left>
					<center><h1>Acknowledgements</h1></center>
					ND is supported by a Academy of Medical Sciences
					Springboard Award. MJ is supported by the National Institute for Health Research, Oxford Biomedical Research
					Centre, and this research was funded by the Wellcome Trust
					[215573/Z/19/Z]. WIN is supported by core funding from
					the Wellcome Trust [203139/Z/16/Z]. AN is grateful for
					support from the Academy of Medical Sciences under the
					Springboard Awards scheme (SBF005/1136), and the Bill
					and Melinda Gates Foundation.

					This template was originally made by <a href="http://web.mit.edu/phillipi/">Phillip Isola</a> and <a href="http://richzhang.github.io/">Richard Zhang</a> for a <a href="http://richzhang.github.io/colorization/">colorful</a> ECCV project; the code can be found <a href="https://github.com/richzhang/webpage-template">here</a>.
				</left>
			</td>
		</tr>
	</table>

<br>
</body>
</html>

